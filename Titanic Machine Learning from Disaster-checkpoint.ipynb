{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a619830f-a538-46bc-a396-c12491d4f931",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 1 with Hyperparameters: {'n_estimators': 50, 'learning_rate': 0.05, 'max_depth': 2, 'random_state': 42}\n",
      "Accuracy: 0.8648648648648649\n",
      "\n",
      "Training Model 2 with Hyperparameters: {'n_estimators': 150, 'learning_rate': 0.2, 'max_depth': 4, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n",
      "\n",
      "Training Model 3 with Hyperparameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n",
      "\n",
      "Training Model 4 with Hyperparameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'random_state': 42}\n",
      "Accuracy: 0.9324324324324325\n",
      "\n",
      "Training Model 5 with Hyperparameters: {'n_estimators': 120, 'learning_rate': 0.1, 'max_depth': 6, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n",
      "\n",
      "Training Model 6 with Hyperparameters: {'n_estimators': 80, 'learning_rate': 0.15, 'max_depth': 3, 'random_state': 42}\n",
      "Accuracy: 0.9324324324324325\n",
      "\n",
      "Training Model 7 with Hyperparameters: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 4, 'random_state': 42}\n",
      "Accuracy: 0.9459459459459459\n",
      "\n",
      "Training Model 8 with Hyperparameters: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n",
      "\n",
      "Training Model 9 with Hyperparameters: {'n_estimators': 150, 'learning_rate': 0.2, 'max_depth': 5, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n",
      "\n",
      "Training Model 10 with Hyperparameters: {'n_estimators': 120, 'learning_rate': 0.15, 'max_depth': 4, 'random_state': 42}\n",
      "Accuracy: 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"C:/Users/Asus/Downloads/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/Asus/Downloads/train.csv\")\n",
    "gender_submission = pd.read_csv(\"C:/Users/Asus/Downloads/gender_submission.csv\")\n",
    "\n",
    "# Combine train and test data\n",
    "combined = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Remove NaN values\n",
    "combined.dropna(inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "# Encoding categorical variables\n",
    "encoder = LabelEncoder()\n",
    "combined['Sex'] = encoder.fit_transform(combined['Sex'])\n",
    "combined['Embarked'] = encoder.fit_transform(combined['Embarked'])\n",
    "\n",
    "# Extract titles from names\n",
    "combined['Title'] = combined['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "combined['Title'] = combined['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr',\n",
    "                                               'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "combined['Title'] = combined['Title'].replace('Mlle', 'Miss')\n",
    "combined['Title'] = combined['Title'].replace('Ms', 'Miss')\n",
    "combined['Title'] = combined['Title'].replace('Mme', 'Mrs')\n",
    "combined['Title'] = encoder.fit_transform(combined['Title'])\n",
    "\n",
    "# Create new feature: Family size\n",
    "combined['FamilySize'] = combined['SibSp'] + combined['Parch'] + 1\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FamilySize']\n",
    "X = combined[features]\n",
    "y = combined['Survived']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define different combinations of hyperparameters\n",
    "hyperparameters = [\n",
    "    {'n_estimators': 50, 'learning_rate': 0.05, 'max_depth': 2, 'random_state': 42},\n",
    "    {'n_estimators': 150, 'learning_rate': 0.2, 'max_depth': 4, 'random_state': 42},\n",
    "    {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'random_state': 42},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'random_state': 42},\n",
    "    {'n_estimators': 120, 'learning_rate': 0.1, 'max_depth': 6, 'random_state': 42},\n",
    "    {'n_estimators': 80, 'learning_rate': 0.15, 'max_depth': 3, 'random_state': 42},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 4, 'random_state': 42},\n",
    "    {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6, 'random_state': 42},\n",
    "    {'n_estimators': 150, 'learning_rate': 0.2, 'max_depth': 5, 'random_state': 42},\n",
    "    {'n_estimators': 120, 'learning_rate': 0.15, 'max_depth': 4, 'random_state': 42}\n",
    "]\n",
    "\n",
    "\n",
    "# Train Gradient Boosting Classifier with different hyperparameter combinations\n",
    "for i, params in enumerate(hyperparameters, start=1):\n",
    "    print(f\"\\nTraining Model {i} with Hyperparameters: {params}\")\n",
    "    \n",
    "    # Initialize Gradient Boosting Classifier with specified hyperparameters\n",
    "    gbt_clf = GradientBoostingClassifier(**params)\n",
    "\n",
    "    # Train the model\n",
    "    gbt_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = gbt_clf.predict(X_val)\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cad5c47-7d8c-4df1-b0d6-680e1a4db33c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Accuracy: 0.972972972972973\n",
      "Hyperparameters of the model with maximum accuracy:\n",
      "{'n_estimators': 150, 'learning_rate': 0.2, 'max_depth': 4, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# Define the accuracies obtained for each model\n",
    "accuracies = [\n",
    "    0.8648648648648649,  # Accuracy of Model 1\n",
    "    0.972972972972973,   # Accuracy of Model 2\n",
    "    0.972972972972973,   # Accuracy of Model 3\n",
    "    0.9324324324324325,  # Accuracy of Model 4\n",
    "    0.972972972972973,   # Accuracy of Model 5\n",
    "    0.9324324324324325,  # Accuracy of Model 6\n",
    "    0.9459459459459459,  # Accuracy of Model 7\n",
    "    0.972972972972973,   # Accuracy of Model 8\n",
    "    0.972972972972973,   # Accuracy of Model 9\n",
    "    0.972972972972973    # Accuracy of Model 10\n",
    "]\n",
    "\n",
    "# Find the index of the model with the highest accuracy\n",
    "index_of_max_accuracy = accuracies.index(max(accuracies))\n",
    "\n",
    "# Print the maximum accuracy and corresponding hyperparameters\n",
    "print(\"Maximum Accuracy:\", max(accuracies))\n",
    "print(\"Hyperparameters of the model with maximum accuracy:\")\n",
    "print(hyperparameters[index_of_max_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabfa92-8462-415b-a178-7854e8b41250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
